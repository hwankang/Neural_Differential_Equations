{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM96wtY9JIgCx2crPJ4dD5I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwankang/Neural_Differential_Equations/blob/master/2_Dec_9_52_pm_2022_torchvison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsEeswQVGVXx"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# 경고 메시지 무시하기\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()   # 반응형 모드"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "filename='/content/drive/MyDrive/machine_learning/123_Raman_DATA_csv.csv'\n",
        "filename_a='/content/drive/MyDrive/machine_learning/B_NIR_DATA_csv.csv'\n",
        "import pandas as pd\n",
        "data_a = pd.read_csv(filename_a,header=0, \n",
        "                   encoding=\"unicode-escape\")"
      ],
      "metadata": {
        "id": "FJhuQMBfI6OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xx,yy=data_a.shape\n",
        "xx"
      ],
      "metadata": {
        "id": "tkUaOYmiJRcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "landmarks_frame=data_a"
      ],
      "metadata": {
        "id": "gVIfDO9xH4aR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "filename='/content/drive/MyDrive/data/faces/face_landmarks.csv'\n",
        "#filename_a='/content/drive/MyDrive/machine_learning/B_NIR_DATA_csv.csv'\n",
        "import pandas as pd\n",
        "#data_a = pd.read_csv(filename_a,header=0, \n",
        "#                  encoding=\"unicode-escape\")\n",
        "landmarks_frame = pd.read_csv(filename)"
      ],
      "metadata": {
        "id": "mXFpJXovdLA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "landmarks_frame\n"
      ],
      "metadata": {
        "id": "rAeS4FlAeSHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 65\n",
        "img_name = landmarks_frame.iloc[n, 0]\n",
        "landmarks = landmarks_frame.iloc[n, 1:]\n",
        "landmarks = np.asarray(landmarks)\n",
        "landmarks = landmarks.astype('float').reshape(-1, 2)"
      ],
      "metadata": {
        "id": "Xr3tOXXKGllE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Image name: {}'.format(img_name))\n",
        "print('Landmarks shape: {}'.format(landmarks.shape))\n",
        "print('First 4 Landmarks: {}'.format(landmarks[:4]))"
      ],
      "metadata": {
        "id": "xYvkR54deDwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "W7wJeTTRimaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def show_landmarks(image, landmarks):\n",
        "    \"\"\"Show image with landmarks\"\"\"\n",
        "    \"\"\" 랜드마크(landmark)와 이미지를 보여줍니다. \"\"\"\n",
        "    #plt.imshow(image)\n",
        "    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r')\n",
        "    plt.pause(0.001)  # 갱신이 되도록 잠시 멈춥니다.\n",
        "\n",
        "plt.figure()\n",
        "#show_landmarks(io.imread(os.path.join('data/faces/', img_name)),\n",
        "#/content/drive/MyDrive/data/faces/\n",
        "show_landmarks(io.imread(os.path.join('drive/MyDrive/data/faces/', img_name)),\n",
        "               landmarks)\n",
        "#show_landmarks(img_name,landmarks)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JT2FEglxJhsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset 클래스"
      ],
      "metadata": {
        "id": "gEPwUP48i2yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceLandmarksDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): csv 파일의 경로\n",
        "            root_dir (string): 모든 이미지가 존재하는 디렉토리 경로\n",
        "            transform (callable, optional): 샘플에 적용될 Optional transform\n",
        "        \"\"\"\n",
        "        self.landmarks_frame = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.landmarks_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir,\n",
        "                                self.landmarks_frame.iloc[idx, 0])\n",
        "        image = io.imread(img_name)\n",
        "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
        "        landmarks = np.array([landmarks])\n",
        "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
        "        sample = {'image': image, 'landmarks': landmarks}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "DeDOwktzjYfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_dataset = FaceLandmarksDataset(csv_file='drive/MyDrive/data/faces/face_landmarks.csv',\n",
        "                                    root_dir='drive/MyDrive/data/faces/')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "for i in range(len(face_dataset)):\n",
        "    sample = face_dataset[i]\n",
        "\n",
        "    print(i, sample['image'].shape, sample['landmarks'].shape)\n",
        "\n",
        "    ax = plt.subplot(1, 4, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title('Sample #{}'.format(i))\n",
        "    ax.axis('off')\n",
        "    show_landmarks(**sample)\n",
        "\n",
        "    if i == 3:\n",
        "        plt.show()\n",
        "        break"
      ],
      "metadata": {
        "id": "mN29SRXSi5ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transforms"
      ],
      "metadata": {
        "id": "Df3eFlO1kSqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Rescale(object):\n",
        "    \"\"\"주어진 크기로 샘플크기를 조정합니다.\n",
        "\n",
        "    Args:\n",
        "        output_size(tuple or int) : 원하는 출력 크기가\n",
        "            tuple인 경우 해당 tuple(output_size)이 결과물(output)의 크기가 되고,\n",
        "            int라면 비율을 유지하면서, 길이가 작은 쪽이 output_size가 됩니다.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, landmarks = sample['image'], sample['landmarks']\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "        if isinstance(self.output_size, int):\n",
        "            if h > w:\n",
        "                new_h, new_w = self.output_size * h / w, self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "\n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "        img = transform.resize(image, (new_h, new_w))\n",
        "\n",
        "        landmarks = landmarks * [new_w / w, new_h / h]\n",
        "\n",
        "        return {'image': img, 'landmarks': landmarks}\n",
        "\n",
        "\n",
        "class RandomCrop(object):\n",
        "    \"\"\"샘플데이터를 무작위로 자릅니다.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): 줄이고자 하는 크기입니다.\n",
        "                        int라면, 정사각형으로 나올 것 입니다.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        if isinstance(output_size, int):\n",
        "            self.output_size = (output_size, output_size)\n",
        "        else:\n",
        "            assert len(output_size) == 2\n",
        "            self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, landmarks = sample['image'], sample['landmarks']\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "        new_h, new_w = self.output_size\n",
        "\n",
        "        top = np.random.randint(0, h - new_h)\n",
        "        left = np.random.randint(0, w - new_w)\n",
        "\n",
        "        image = image[top: top + new_h,\n",
        "                      left: left + new_w]\n",
        "\n",
        "        landmarks = landmarks - [left, top]\n",
        "\n",
        "        return {'image': image, 'landmarks': landmarks}\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"numpy array를 tensor(torch)로 변환 시켜줍니다.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, landmarks = sample['image'], sample['landmarks']\n",
        "\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C\n",
        "        # torch image: C x H x W\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        return {'image': torch.from_numpy(image),\n",
        "                'landmarks': torch.from_numpy(landmarks)}"
      ],
      "metadata": {
        "id": "L6fxUpPrjlVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Compose transforms"
      ],
      "metadata": {
        "id": "-tbGGBeBlNKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scale = Rescale(256)\n",
        "crop = RandomCrop(128)\n",
        "composed = transforms.Compose([Rescale(256),\n",
        "                               RandomCrop(224)])\n",
        "\n",
        "# Apply each of the above transforms on sample.\n",
        "fig = plt.figure()\n",
        "sample = face_dataset[65]\n",
        "for i, tsfrm in enumerate([scale, crop, composed]):\n",
        "    transformed_sample = tsfrm(sample)\n",
        "\n",
        "    ax = plt.subplot(1, 3, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title(type(tsfrm).__name__)\n",
        "    show_landmarks(**transformed_sample)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aM2Y9vkWlQNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##데이터셋을 이용한 반복작업 "
      ],
      "metadata": {
        "id": "iEN9A56-lzP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_dataset = FaceLandmarksDataset(csv_file='drive/MyDrive/data/faces/face_landmarks.csv',\n",
        "                                           root_dir='drive/MyDrive/data/faces/',\n",
        "                                           transform=transforms.Compose([\n",
        "                                               Rescale(256),\n",
        "                                               RandomCrop(224),\n",
        "                                               ToTensor()\n",
        "                                           ]))\n",
        "\n",
        "for i in range(len(transformed_dataset)):\n",
        "    sample = transformed_dataset[i]\n",
        "\n",
        "    print(i, sample['image'].size(), sample['landmarks'].size())\n",
        "\n",
        "    if i == 3:\n",
        "        break"
      ],
      "metadata": {
        "id": "2Gy-yi-elUPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(transformed_dataset, batch_size=4,\n",
        "                        shuffle=True, num_workers=0)\n",
        "\n",
        "\n",
        "# 배치하는 과정을 보여주는 함수입니다.\n",
        "def show_landmarks_batch(sample_batched):\n",
        "    \"\"\"Show image with landmarks for a batch of samples.\"\"\"\n",
        "    images_batch, landmarks_batch = \\\n",
        "            sample_batched['image'], sample_batched['landmarks']\n",
        "    batch_size = len(images_batch)\n",
        "    im_size = images_batch.size(2)\n",
        "    grid_border_size = 2\n",
        "\n",
        "    grid = utils.make_grid(images_batch)\n",
        "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size + (i + 1) * grid_border_size,\n",
        "                    landmarks_batch[i, :, 1].numpy() + grid_border_size,\n",
        "                    s=10, marker='.', c='r')\n",
        "\n",
        "        plt.title('Batch from dataloader')\n",
        "\n",
        "# Windows를 사용 중이라면, 다음 줄의 주석을 제거하고 for 반복문을 들여쓰기합니다.\n",
        "# \"num_workers\"를 0으로 변경해야 할 수도 있습니다.\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "for i_batch, sample_batched in enumerate(dataloader):\n",
        "    print(i_batch, sample_batched['image'].size(),\n",
        "          sample_batched['landmarks'].size())\n",
        "\n",
        "    # observe 4th batch and stop.\n",
        "    if i_batch == 3:\n",
        "        plt.figure()\n",
        "        show_landmarks_batch(sample_batched)\n",
        "        plt.axis('off')\n",
        "        plt.ioff()\n",
        "        plt.show()\n",
        "        break"
      ],
      "metadata": {
        "id": "hN0rnxfqmwqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BH1TTydglhqk"
      }
    }
  ]
}